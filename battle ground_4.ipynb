{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chart_studio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d89b7af48309>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mchart_studio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotly\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcufflinks\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgo_offline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chart_studio'"
     ]
    }
   ],
   "source": [
    "#adjusted copy of https://www.kaggle.com/ceshine/a-simple-post-processing-trick-lb-0237-0204/code\n",
    "import gc\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from builtins import list\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    #start_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    #end_mem = df.memory_usage().sum() / 1024**2\n",
    "    #print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    #print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    print(\"Loading data from input files\")\n",
    "    \n",
    "    print(\"Parts of the prediction\")\n",
    "    # Any results you write to the current directory are saved as output.\n",
    "    #df_sub = pd.read_csv(\"../input/random-forest-regressor/rfr_submission_2_score_0.029005332340924082.csv\")\n",
    "    df_sub = pd.read_csv(\"../input/pubg-lgbm-regressor-fork/lgbm_submission_1.csv\") # ../input/pubg-lgbm-regressor/   pubg-lgbm-regressor-fork\n",
    "    df_sub2 = pd.read_csv(\"../input/pubg-lgbm-regressor-fork/lgbm_submission_2.csv\")\n",
    "    print(\"Merge 1\")\n",
    "    df_sub = df_sub.append(df_sub2, sort=False, ignore_index=True)\n",
    "    del df_sub2\n",
    "    df_sub2 = None\n",
    "    df_sub2 = pd.read_csv(\"../input/pubg-lgbm-regressor-fork/lgbm_submission_3.csv\")\n",
    "    print(\"Merge 2\")\n",
    "    df_sub = df_sub.append(df_sub2, sort=False, ignore_index=True)\n",
    "    del df_sub2\n",
    "    df_sub2 = None\n",
    "    \n",
    "    df_sub.to_csv(\"lgbm_submission_4_raw.csv\", index=False)\n",
    "    \n",
    "    # df_sub = reduce_mem_usage(df_sub)\n",
    "    \n",
    "    print(\"Test data...\")\n",
    "    df_test = pd.read_csv(\"../input/pubg-finish-placement-prediction/test_V2.csv\") # ../input/pubg-finish-placement-prediction/\n",
    "    # df_test = reduce_mem_usage(df_test)\n",
    "    \n",
    "    # Restore some columns\n",
    "    df_sub = df_sub.merge(df_test[[\"Id\", \"matchId\", \"groupId\", \"killPlace\",\"maxPlace\", \"killPoints\", \"rankPoints\", \"winPoints\", \"numGroups\", \"kills\"]], on=\"Id\", how=\"left\")\n",
    "    df_sub[\"killPlace_2\"] = -df_sub[\"killPlace\"]\n",
    "    df_sub[\"points_sum\"] = df_sub[\"killPoints\"] + df_sub[\"rankPoints\"] + df_sub[\"winPoints\"]\n",
    "    df_sub[\"missing_groups_perc\"] = (df_sub[\"maxPlace\"] - df_sub[\"numGroups\"]) / df_sub[\"maxPlace\"]\n",
    "    # df_sub.drop(columns=\"killPlace\", inplace=True)\n",
    "    df_sub.drop(columns=\"killPoints\", inplace=True)\n",
    "    df_sub.drop(columns=\"rankPoints\", inplace=True)\n",
    "    df_sub.drop(columns=\"winPoints\", inplace=True)\n",
    "    # df_sub = reduce_mem_usage(df_sub)\n",
    "    \n",
    "    del df_test\n",
    "    df_test = None\n",
    "    gc.collect()\n",
    "    \n",
    "    # unify team results, just in case\n",
    "    # df_sub['tean_avg_winPlacePerc'] = df_sub.groupby([\"matchId\", \"groupId\"])['winPlacePerc'].transform('mean')\n",
    "    # df_sub[\"winPlacePerc\"] = df_sub[\"tean_avg_winPlacePerc\"]\n",
    "    # df_sub.drop(labels=\"tean_avg_winPlacePerc\", axis=1, inplace=True)\n",
    "    \n",
    "    # Deal with edge cases\n",
    "    df_sub.loc[df_sub.maxPlace == 0, \"winPlacePerc\"] = 0\n",
    "    df_sub.loc[df_sub.maxPlace == 1, \"winPlacePerc\"] = 1\n",
    "    # Edge case\n",
    "    df_sub.loc[(df_sub.maxPlace > 1) & (df_sub.numGroups == 1), \"winPlacePerc\"] = 0\n",
    "    \n",
    "    # just in case\n",
    "    df_sub.loc[df_sub.winPlacePerc < 0, \"winPlacePerc\"] = 0\n",
    "    df_sub.loc[df_sub.winPlacePerc > 1, \"winPlacePerc\"] = 1\n",
    "    \n",
    "    # check for same place for different teams\n",
    "    print(\"Checking for anomalies in the winPlacePerc - every group should have different score\")\n",
    "    df_sub[\"group_size\"] = df_sub.groupby([\"matchId\", \"groupId\"])['Id'].transform('count')\n",
    "    df_sub['winPlacePerc_size'] = df_sub.groupby([\"matchId\", 'winPlacePerc'])['Id'].transform('count')\n",
    "    df_sub['winPlacePerc_size'] = df_sub['winPlacePerc_size'] / df_sub[\"group_size\"]\n",
    "    \n",
    "    df_sub_2 = df_sub[df_sub[\"winPlacePerc_size\"] != 1.0]\n",
    "    \n",
    "    print(\"Size of anomalies: \" + str(len(df_sub_2)))\n",
    "    \n",
    "    if len(df_sub_2) > 0:\n",
    "        df_sub_2.sort_values(ascending=False, by=[\"matchId\", \"winPlacePerc\", \"killPlace_2\", \"maxPlace\", \"points_sum\", \"groupId\"], inplace=True)\n",
    "    \n",
    "        prev_match = \"match_XXXX\"\n",
    "            \n",
    "        for i in tqdm(range(len(df_sub_2)), desc=\"Correcting equal winPlacePerc\", mininterval=2):\n",
    "            row =  df_sub_2.iloc[i]\n",
    "        #     print('matchId: ' + row[\"matchId\"] + \", groupId: \" + row[\"groupId\"])\n",
    "            if prev_match != row[\"matchId\"]:\n",
    "        #         print(\"New match!!!\")\n",
    "                mods = dict()\n",
    "                next_penalty = 0.0\n",
    "                group_to_skip = None\n",
    "            prev_match = row[\"matchId\"]\n",
    "            \n",
    "            # if \"solo\" in row[\"matchType\"]:\n",
    "            #     continue\n",
    "            \n",
    "            if row[\"groupId\"] in mods.keys():\n",
    "                penalty = mods[row[\"groupId\"]]\n",
    "        #         print(\"Penalty from cache: \" + str(penalty))\n",
    "            else:\n",
    "                if group_to_skip == None:\n",
    "                    group_to_skip = row[\"groupId\"]\n",
    "                elif group_to_skip != row[\"groupId\"]:\n",
    "                    next_penalty = next_penalty + 0.00001\n",
    "                    penalty = next_penalty\n",
    "                    mods[row[\"groupId\"]] = penalty\n",
    "        #             print(\"New penalty: \" + str(penalty))\n",
    "            if group_to_skip != row[\"groupId\"]: \n",
    "                # df_sub.loc[(df_sub[\"Id\"] == row[\"Id\"]) & (df_sub[\"matchId\"] == row[\"matchId\"]) & (df_sub[\"groupId\"] == row[\"groupId\"]), \"winPlacePerc\"] = df_sub_2.winPlacePerc.iloc[i] - penalty\n",
    "                df_sub_2.winPlacePerc.iloc[i] = df_sub_2.winPlacePerc.iloc[i] - penalty\n",
    "                \n",
    "        print(\"Updating winPlacePerc\")\n",
    "        df_sub.loc[df_sub[\"winPlacePerc_size\"] != 1.0, \"winPlacePerc\"] = df_sub_2[\"winPlacePerc\"]\n",
    "        del df_sub_2\n",
    "        df_sub_2 = None\n",
    "        \n",
    "        gc.collect()\n",
    "            \n",
    "        \n",
    "        print(\"Finished correcting winPlacePerc\")\n",
    "    \n",
    "    df_sub_2 = None\n",
    "    \n",
    "    # df_sub.drop(labels=[\"group_size\"], axis=1, inplace=True)\n",
    "    df_sub.drop(labels=[\"winPlacePerc_size\"], axis=1, inplace=True)\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    # based on observation from https://www.kaggle.com/plasticgrammer/pubg-finish-placement-prediction-playground\n",
    "    print()\n",
    "    print(\"Checking for anomalies in the winPlacePerc - players with same number of kills should have scores in order of killPlace\")\n",
    "    \n",
    "    do_correct = True\n",
    "    iteration_number = 1\n",
    "    \n",
    "    while do_correct & (iteration_number <= 1000):\n",
    "        df_sub.sort_values(ascending=False, by=[\"matchId\", \"kills\", \"killPlace\", \"winPlacePerc\", \"groupId\"], inplace=True)\n",
    "        df_sub[\"winPlacePerc_diff\"] = df_sub[\"winPlacePerc\"].diff()\n",
    "        df_sub[\"kills_diff\"] = df_sub[\"kills\"].diff()\n",
    "        df_sub[\"prev_matchId\"] = df_sub[\"matchId\"].shift(1)\n",
    "        df_sub[\"prev_groupId\"] = df_sub[\"groupId\"].shift(1)\n",
    "        df_sub[\"prev_winPlacePerc\"] = df_sub[\"winPlacePerc\"].shift(1)\n",
    "        \n",
    "        df_sub2 = df_sub[(df_sub[\"winPlacePerc_diff\"] < 0) & (df_sub[\"kills_diff\"] == 0) & (df_sub[\"matchId\"] == df_sub[\"prev_matchId\"])]\n",
    "        anomalies_count = len(df_sub2)\n",
    "        \n",
    "        print(\"Iteration \" + str(iteration_number) + \" Anomalies count: \" + str(anomalies_count))\n",
    "        \n",
    "        changed_groups = list()\n",
    "        \n",
    "        if anomalies_count > 0:\n",
    "            print()\n",
    "            print(\"Looking for pairs to change...\")\n",
    "            \n",
    "            df_sub2[\"new_winPlacePerc\"] = df_sub2[\"winPlacePerc\"] \n",
    "            \n",
    "            df_sub3 = pd.DataFrame()\n",
    "            \n",
    "            for i in tqdm(range(1, min(15001, max(anomalies_count, 2))), desc=\"Identifying unique groups\", mininterval=10):\n",
    "                row = df_sub2.iloc[i - 1]\n",
    "                    \n",
    "                id_prev = str(row[\"prev_matchId\"]) + \"!\" + str(row[\"prev_groupId\"])\n",
    "                id_cur = str(row[\"matchId\"]) + \"!\" + str(row[\"groupId\"])\n",
    "                \n",
    "                if (not id_prev in changed_groups) & (not id_cur in changed_groups):\n",
    "                    changed_groups.append(id_prev)\n",
    "                    changed_groups.append(id_cur)\n",
    "                    \n",
    "                    df_sub3 = df_sub3.append({\"matchId\" : row[\"matchId\"], \"groupId\" : row[\"prev_groupId\"], \"new_winPlacePerc\" : row[\"winPlacePerc\"]}, sort=False, ignore_index=True)\n",
    "                    df_sub3 = df_sub3.append({\"matchId\" : row[\"matchId\"], \"groupId\" : row[\"groupId\"], \"new_winPlacePerc\" : row[\"prev_winPlacePerc\"]}, sort=False, ignore_index=True)\n",
    "            \n",
    "            df_sub3.drop_duplicates(inplace=True)\n",
    "            df_sub = df_sub.merge(df_sub3, on=[\"matchId\", \"groupId\"], how=\"left\")\n",
    "            df_sub.loc[df_sub[\"new_winPlacePerc\"].notna(), \"winPlacePerc\"] = df_sub.loc[df_sub[\"new_winPlacePerc\"].notna()][\"new_winPlacePerc\"]       \n",
    "            df_sub.drop(labels=\"new_winPlacePerc\", axis=1, inplace=True)\n",
    "            del df_sub2\n",
    "            del df_sub3\n",
    "            df_sub2 = None\n",
    "            df_sub3 = None\n",
    "            gc.collect()\n",
    "        else:\n",
    "            do_correct = False\n",
    "        \n",
    "        iteration_number = iteration_number + 1\n",
    "        \n",
    "    if do_correct:\n",
    "        print(\"Limit of iterations reached...\")\n",
    "    \n",
    "    print(\"Finished correcting winPlacePerc\")\n",
    "    \n",
    "    # print()\n",
    "    # print()\n",
    "    # print(\"Adjusting winPlacePerc with its rank and numGroups and then with maxPlace where missing groups percentage > 0.6\")\n",
    "    # # Sort, rank, and assign adjusted ratio\n",
    "    # df_sub_group = df_sub.loc[df_sub[\"missing_groups_perc\"] < 0.6].groupby([\"matchId\", \"groupId\"]).first().reset_index()\n",
    "    # df_sub_group[\"rank\"] = df_sub_group.groupby([\"matchId\"])[\"winPlacePerc\"].rank()\n",
    "    # df_sub_group = df_sub_group.merge(\n",
    "    #     df_sub_group.groupby(\"matchId\")[\"rank\"].max().to_frame(\"max_rank\").reset_index(), \n",
    "    #     on=\"matchId\", how=\"left\")\n",
    "    # df_sub_group[\"adjusted_perc\"] = (df_sub_group[\"rank\"] - 1) / (df_sub_group[\"numGroups\"] - 1)\n",
    "    \n",
    "    # # Align with maxPlace\n",
    "    # # Credit: https://www.kaggle.com/anycode/simple-nn-baseline-4\n",
    "    # subset = df_sub_group.loc[df_sub_group.maxPlace > 1]\n",
    "    # gap = 1.0 / (subset.maxPlace.values - 1)\n",
    "    # new_perc = np.around(subset.winPlacePerc.values / gap) * gap\n",
    "    # df_sub_group.loc[df_sub_group.maxPlace > 1, \"winPlacePerc\"] = new_perc\n",
    "    \n",
    "    # df_sub = df_sub.merge(df_sub_group[[\"adjusted_perc\", \"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")\n",
    "    # df_sub.loc[df_sub[\"missing_groups_perc\"] < 0.6, \"winPlacePerc\"] = df_sub.loc[df_sub[\"missing_groups_perc\"] < 0.6][\"adjusted_perc\"]\n",
    "    \n",
    "    # del df_sub_group\n",
    "    # df_sub_group = None\n",
    "    # gc.collect()\n",
    "    \n",
    "    # print()\n",
    "    # print()\n",
    "    # print(\"Fixing placing where missing groups percentage > 0.6\")\n",
    "    \n",
    "    # print()\n",
    "    # print(\"Aligning against maxPlace\")\n",
    "    \n",
    "    # df_sub.loc[df_sub[\"missing_groups_perc\"] > 0.6, \"winPlacePerc\"] = 1.0 - df_sub.loc[df_sub[\"missing_groups_perc\"] > 0.6][\"winPlacePerc\"]\n",
    "    # subset = df_sub.loc[df_sub[\"missing_groups_perc\"] > 0.6]\n",
    "    \n",
    "    # subset[\"gap\"] = 1.0 / (subset[\"maxPlace\"] - 1)\n",
    "    # subset[\"aligned_winPlacePerc\"] = np.around(subset[\"winPlacePerc\"] / subset[\"gap\"])# * subset[\"gap\"]\n",
    "    # subset[\"aligned_winPlacePerc\"] = subset[\"aligned_winPlacePerc\"].astype(int)\n",
    "    \n",
    "    # print(\"Phase 1 - pushing down\")\n",
    "    \n",
    "    # do_correct = True\n",
    "    # iteration_number = 1\n",
    "    \n",
    "    # while do_correct & (iteration_number <= 1000):\n",
    "    #     subset.sort_values(ascending=False, by=[\"matchId\", \"aligned_winPlacePerc\", \"winPlacePerc\", \"groupId\"], inplace=True)\n",
    "        \n",
    "    #     subset[\"aligned_winPlacePerc_diff\"] = subset[\"aligned_winPlacePerc\"].diff()\n",
    "    #     subset[\"prev_matchId\"] = subset[\"matchId\"].shift(1)\n",
    "    #     subset[\"prev_groupId\"] = subset[\"groupId\"].shift(1)\n",
    "    #     subset[\"prev_aligned_winPlacePerc\"] = subset[\"aligned_winPlacePerc\"].shift(1)\n",
    "        \n",
    "    #     df_sub2 = subset[(subset[\"aligned_winPlacePerc_diff\"] == 0) & (subset[\"groupId\"] != subset[\"prev_groupId\"]) & (subset[\"matchId\"] == subset[\"prev_matchId\"])]\n",
    "    #     anomalies_count = len(df_sub2)\n",
    "        \n",
    "    #     print(\"Iteration \" + str(iteration_number) + \" Anomalies count: \" + str(anomalies_count))\n",
    "        \n",
    "    #     if anomalies_count > 0:\n",
    "            \n",
    "    #         df_sub2[\"new_aligned_winPlacePerc\"] = df_sub2[\"aligned_winPlacePerc\"] - 1\n",
    "            \n",
    "    #         df_sub2 = df_sub2[[\"new_aligned_winPlacePerc\", \"matchId\", \"groupId\"]]\n",
    "    #         df_sub2.drop_duplicates(inplace=True)\n",
    "            \n",
    "    #         subset = subset.merge(df_sub2, on=[\"matchId\", \"groupId\"], how=\"left\")\n",
    "    #         subset.loc[subset[\"new_aligned_winPlacePerc\"].notna(), \"aligned_winPlacePerc\"] = subset.loc[subset[\"new_aligned_winPlacePerc\"].notna()][\"new_aligned_winPlacePerc\"]\n",
    "    #         subset.drop(labels=\"new_aligned_winPlacePerc\", axis=1, inplace=True)\n",
    "    #         del df_sub2\n",
    "    #         df_sub2 = None\n",
    "    #         gc.collect()\n",
    "    #     else:\n",
    "    #         do_correct = False\n",
    "        \n",
    "    #     iteration_number = iteration_number + 1\n",
    "        \n",
    "    # if do_correct:\n",
    "    #     print(\"Limit of iterations reached...\")\n",
    "    \n",
    "    \n",
    "    # print(\"Phase 2 - pushing up where < 0\")\n",
    "    \n",
    "    # subset.loc[subset[\"aligned_winPlacePerc\"] < 0, \"aligned_winPlacePerc\"] = 0\n",
    "    \n",
    "    \n",
    "    # print(\"Phase 3 - pushing up\")\n",
    "    \n",
    "    # do_correct = True\n",
    "    # iteration_number = 1\n",
    "    \n",
    "    # while do_correct & (iteration_number <= 1000):\n",
    "    #     subset.sort_values(ascending=True, by=[\"matchId\", \"aligned_winPlacePerc\", \"winPlacePerc\", \"groupId\"], inplace=True)\n",
    "        \n",
    "    #     subset[\"aligned_winPlacePerc_diff\"] = subset[\"aligned_winPlacePerc\"].diff()\n",
    "    #     subset[\"prev_matchId\"] = subset[\"matchId\"].shift(1)\n",
    "    #     subset[\"prev_groupId\"] = subset[\"groupId\"].shift(1)\n",
    "    #     subset[\"prev_aligned_winPlacePerc\"] = subset[\"aligned_winPlacePerc\"].shift(1)\n",
    "        \n",
    "    #     df_sub2 = subset[(subset[\"aligned_winPlacePerc_diff\"] == 0) & (subset[\"groupId\"] != subset[\"prev_groupId\"]) & (subset[\"matchId\"] == subset[\"prev_matchId\"])]\n",
    "    #     anomalies_count = len(df_sub2)\n",
    "        \n",
    "    #     print(\"Iteration \" + str(iteration_number) + \" Anomalies count: \" + str(anomalies_count))\n",
    "        \n",
    "    #     if anomalies_count > 0:\n",
    "            \n",
    "    #         df_sub2[\"new_aligned_winPlacePerc\"] = df_sub2[\"aligned_winPlacePerc\"] + 1\n",
    "            \n",
    "    #         df_sub2 = df_sub2[[\"new_aligned_winPlacePerc\", \"matchId\", \"groupId\"]]\n",
    "    #         df_sub2.drop_duplicates(inplace=True)\n",
    "            \n",
    "    #         subset = subset.merge(df_sub2, on=[\"matchId\", \"groupId\"], how=\"left\")\n",
    "    #         subset.loc[subset[\"new_aligned_winPlacePerc\"].notna(), \"aligned_winPlacePerc\"] = subset.loc[subset[\"new_aligned_winPlacePerc\"].notna()][\"new_aligned_winPlacePerc\"]\n",
    "    #         subset.drop(labels=\"new_aligned_winPlacePerc\", axis=1, inplace=True)\n",
    "    #         del df_sub2\n",
    "    #         df_sub2 = None\n",
    "    #         gc.collect()\n",
    "    #     else:\n",
    "    #         do_correct = False\n",
    "        \n",
    "    #     iteration_number = iteration_number + 1\n",
    "        \n",
    "    # if do_correct:\n",
    "    #     print(\"Limit of iterations reached...\")\n",
    "    \n",
    "    # subset[\"aligned_winPlacePerc\"] = subset[\"aligned_winPlacePerc\"] * subset[\"gap\"]\n",
    "    # print(\"Number of negative scores: \" + str(len(subset.loc[subset[\"aligned_winPlacePerc\"] < 0])))\n",
    "    # print(\"Number of scores greater then 1: \" + str(len(subset.loc[subset[\"aligned_winPlacePerc\"] > 1])))\n",
    "    # subset = subset[[\"aligned_winPlacePerc\", \"matchId\", \"groupId\"]]\n",
    "    # subset.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # df_sub = df_sub.merge(subset, on=[\"matchId\", \"groupId\"], how=\"left\")\n",
    "    # df_sub.loc[df_sub[\"aligned_winPlacePerc\"].notna(), \"winPlacePerc\"] = df_sub.loc[df_sub[\"aligned_winPlacePerc\"].notna()][\"aligned_winPlacePerc\"]\n",
    "    \n",
    "    # print(\"Finished fixing placing where numGroups < maxPlace\")\n",
    "    \n",
    "    # original alinging code\n",
    "    print(\"Adjusting winPlacePerc with its rank and numGroups\")\n",
    "    # Sort, rank, and assign adjusted ratio\n",
    "    df_sub_group = df_sub.groupby([\"matchId\", \"groupId\"]).first().reset_index()\n",
    "    df_sub_group[\"rank\"] = df_sub_group.groupby([\"matchId\"])[\"winPlacePerc\"].rank()\n",
    "    df_sub_group = df_sub_group.merge(\n",
    "        df_sub_group.groupby(\"matchId\")[\"rank\"].max().to_frame(\"max_rank\").reset_index(), \n",
    "        on=\"matchId\", how=\"left\")\n",
    "    df_sub_group[\"adjusted_perc\"] = (df_sub_group[\"rank\"] - 1) / (df_sub_group[\"numGroups\"] - 1)\n",
    "    \n",
    "    df_sub = df_sub.merge(df_sub_group[[\"adjusted_perc\", \"matchId\", \"groupId\"]], on=[\"matchId\", \"groupId\"], how=\"left\")\n",
    "    df_sub[\"winPlacePerc\"] = df_sub[\"adjusted_perc\"]\n",
    "    \n",
    "    print(\"Aligning with maxPlace\")\n",
    "    # Align with maxPlace\n",
    "    # Credit: https://www.kaggle.com/anycode/simple-nn-baseline-4\n",
    "    subset = df_sub.loc[df_sub.maxPlace > 1]\n",
    "    gap = 1.0 / (subset.maxPlace.values - 1)\n",
    "    new_perc = np.around(subset.winPlacePerc.values / gap) * gap\n",
    "    df_sub.loc[df_sub.maxPlace > 1, \"winPlacePerc\"] = new_perc\n",
    "    \n",
    "    # Edge case\n",
    "    df_sub.loc[df_sub.maxPlace == 0, \"winPlacePerc\"] = 0\n",
    "    df_sub.loc[df_sub.maxPlace == 1, \"winPlacePerc\"] = 1\n",
    "    df_sub.loc[(df_sub.maxPlace > 1) & (df_sub.numGroups == 1), \"winPlacePerc\"] = 0\n",
    "    \n",
    "    #another constant cases\n",
    "    subset = df_sub.loc[(df_sub.maxPlace > 1) & (df_sub.numGroups == 2)]\n",
    "    subset[\"group_size_rank\"] = subset.groupby([\"matchId\", \"groupId\"])[\"group_size\"].rank(ascending=True, pct=False)\n",
    "    subset = subset.merge(\n",
    "        subset.groupby(\"matchId\")[\"group_size_rank\"].max().to_frame(\"group_size_max_rank\").reset_index(), \n",
    "        on=\"matchId\", how=\"left\")\n",
    "    subset.loc[subset[\"group_size_rank\"] != subset[\"group_size_max_rank\"], \"winPlacePerc\"] = 1\n",
    "    subset.loc[subset[\"group_size_rank\"] == subset[\"group_size_max_rank\"], \"winPlacePerc\"] = 0\n",
    "    subset[\"new_winPlacePerc2\"] = subset[\"winPlacePerc\"]\n",
    "    df_sub = df_sub.merge(subset[[\"Id\", \"matchId\", \"groupId\", \"new_winPlacePerc2\"]], on=[\"Id\", \"matchId\", \"groupId\"], how=\"left\")\n",
    "    df_sub.loc[df_sub[\"new_winPlacePerc2\"].notna(), \"winPlacePerc\"] = df_sub.loc[df_sub[\"new_winPlacePerc2\"].notna()][\"new_winPlacePerc2\"]\n",
    "    \n",
    "    assert df_sub[\"winPlacePerc\"].isnull().sum() == 0\n",
    "    # df_sub[\"winPlacePerc\"] = np.around(df_sub[\"winPlacePerc\"], decimals=4)\n",
    "    \n",
    "    print(\"Storing final submission to file...\")\n",
    "    df_sub[[\"Id\", \"winPlacePerc\"]].to_csv(\"lgbm_submission_4_adjusted.csv\", index=False)\n",
    "    \n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
